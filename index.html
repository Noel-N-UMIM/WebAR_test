<html>
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <!-- CHANGED: Downgraded to A-Frame 1.4.2 for better compatibility with MindAR 1.2.5 -->
    <script src="https://aframe.io/releases/1.4.2/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.5/dist/mindar-image-aframe.prod.js"></script>

    <script>
      // 1. Register Component with Smart Smoothing
      AFRAME.registerComponent('follow-target', {
        schema: {
          target: { type: 'selector' },
          isTracking: { type: 'boolean', default: false },
          smoothFactor: { type: 'number', default: 1.0 } // 0.1 = smooth/heavy, 1.0 = instant/jittery
        },
        
        init: function() {
          // Initialize helper vectors to avoid garbage collection overhead
          this.targetPos = new THREE.Vector3();
          this.targetQuat = new THREE.Quaternion();
          this.targetScale = new THREE.Vector3();
        },

        tick: function (time, timeDelta) {
          // If tracking is off or target isn't visible, do nothing
          if (!this.data.isTracking) return;
          
          const targetEl = this.data.target;
          if (!targetEl || !targetEl.object3D.visible) return;

          const elObj = this.el.object3D;
          const targetObj = targetEl.object3D;

          // 1. READ: Get the new raw data from the scanner
          targetObj.getWorldPosition(this.targetPos);
          targetObj.getWorldQuaternion(this.targetQuat);
          targetObj.getWorldScale(this.targetScale);

          // 2. CHECK: Distance snap
          // If the object is extremely far away (e.g., first frame), snap instantly.
          // Otherwise, smooth.
          const dist = elObj.position.distanceTo(this.targetPos);
          if (dist > 2) {
             // Snap instantly if far (prevents "flying in" from zero)
             elObj.position.copy(this.targetPos);
             elObj.quaternion.copy(this.targetQuat);
             elObj.scale.copy(this.targetScale);
          } else {
             // 3. SMOOTH: "Educated Guess" Logic
             // We use Lerp (Linear Interpolation) and Slerp (Spherical Interpolation).
             // By moving only 10% (0.1) per frame, we filter out high-frequency noise (jitter).
             // If the scanner mistakenly reports a "vertical" angle for 1-2 frames, 
             // this logic will barely rotate the model before the scanner corrects itself.
             
             const factor = this.data.smoothFactor;
             
             elObj.position.lerp(this.targetPos, factor);
             elObj.quaternion.slerp(this.targetQuat, factor);
             elObj.scale.lerp(this.targetScale, factor);
          }
        },
        
        startTracking: function () {
          this.data.isTracking = true;
          this.el.setAttribute('visible', 'true');
        },
        
        stopTracking: function () {
          this.data.isTracking = false;
          // We do NOT hide it here, so it stays "frozen" at last known spot
        }
      });

      // 2. Wait for DOM to load before querying elements
      document.addEventListener("DOMContentLoaded", function() {
        const exampleTarget = document.querySelector('#example-target');
        const content = document.querySelector('#persistent-content');

        // Check if elements exist to prevent crashes
        if(exampleTarget && content) {
          
          exampleTarget.addEventListener("targetFound", event => {
            console.log("Target Found");
            content.components['follow-target'].startTracking();
          });

          exampleTarget.addEventListener("targetLost", event => {
            console.log("Target Lost");
            content.components['follow-target'].stopTracking();
          });
          
        } else {
          console.error("Critical: Target or Content element not found in DOM.");
        }
      });
    </script>
  </head>
  <body>
    <!-- CHANGED: Updated mindar-image settings to improve tracking tolerance and remove restricted UI -->
    <!-- uiScanning: no -> Removes the small "square" overlay so users know they can scan anywhere. -->
    <!-- missTolerance: 10 -> Wait 10 frames before deciding target is lost (prevents flickering). -->
    <!-- warmupTolerance: 5 -> Wait 5 frames before deciding target is found (prevents false positives). -->
    <a-scene 
      mindar-image="imageTargetSrc: targets.mind; uiScanning: no; missTolerance: 5; warmupTolerance: 1;" 
      color-space="sRGB" 
      renderer="colorManagement: true, physicallyCorrectLights" 
      vr-mode-ui="enabled: false" 
      device-orientation-permission-ui="enabled: false">
      
      <a-assets>
        <!-- I corrected the IDs used below to match these -->
        <img id="card" src="card_MindAR.png" />
        <a-asset-item id="avatarModel" src="https://cdn.jsdelivr.net/gh/hiukim/mind-ar-js@1.2.5/examples/image-tracking/assets/card-example/softmind/scene.gltf"></a-asset-item>
      </a-assets>

      <a-camera position="0 0 0" look-controls="enabled: false"></a-camera>

      <!-- The Target -->
      <a-entity id="example-target" mindar-image-target="targetIndex: 0"></a-entity>
      
      <!-- The Content -->
      <!-- Added follow-target component here -->
      <a-entity 
        id="persistent-content" 
        visible="false" 
        follow-target="target: #example-target">
        
        <!-- Replaced invalid #myModel with #avatarModel -->
        <a-gltf-model src="#avatarModel" scale="0.005 0.005 0.005"></a-gltf-model> 
        
      </a-entity>

    </a-scene>
  </body>
</html>

